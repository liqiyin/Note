# 人工智能学习笔记

## 两种机器学习

### 1.Supervised Learning(监督学习)

```
训练数据集是有明确区别的
```

* 回归问题(regression problem) 连续问题
* 分类(classification) 离散问题, 若干特征, 训练集

### 2.Unsupervised Learning(非监督学习)

```
训练数据集无明确区别,杂乱的数据,需要机器学习去找出其中的区别
```

* 杂乱数据集的分类问题
* 鸡尾酒宴问题(麦克风中包含两种声音源,机器学习能够将其区分并剥离出来)

## 数据清洗和转化

* 1-of-k方法

```
将类别数据编码转化为对应的数值表示
```

* 词带法

```
将文本当做一个无序的集合,文本特征可以采用文本中的词条T进行体现,那么文本中出现的所有词条及其出现的次数就可以体现文档的特征
```

* TF-IDF

```
词条的重要性随着它在`文件`中出现的次数成正比增加,但同时会随着它在`语料库(训练集)`中出现的频率成反比下降;也就是说词条在`文本`中出现的次数越多,表示该词条对该文本的重要性越高;词条在`所有文本`中出现的次数越少,说明词条对文本的重要性越高.TF(词频)指某个词条在`文本`中出现的次数,一般会将其进行归一化处理(该词条的数量/该文档中所有词条的数量);IDF(逆向文件频率)指一个词条重要性的度量,一般计算方式为`ln(总文件数目/包含该词条的文件数目)`.TF-IDF实际上是:TF*IDF
```